{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 6476 - Fall 2020 - Project 1: Image Filtering and Hybrid Images\n",
    "\n",
    "## Brief\n",
    "* Due:\n",
    "  * 09/19/2020 11:59PM\n",
    "\n",
    "* Hand-in: through Gradescope\n",
    "* Required files:\n",
    "  * `<your_gt_username>.zip` against Project 1 - Code on [Gradescope](https://www.gradescope.com/courses/155064/assignments/590378)\n",
    "  * `<yout_gt_username>.pdf` against Project 1 - Report on [Gradescope](https://www.gradescope.com/courses/155064/assignments/601658)\n",
    "  \n",
    "All projects in this course will be done with these iPython notebooks. These are convenient ways for you to quickly and easily interact with the code. A notebook contains many blocks of code, each of which can be run independently. You can run a cell with ctrl+enter or shift+enter (to move to the next cell).\n",
    "\n",
    "## Working Alone\n",
    "\n",
    "If you decide to WORK ALONE, you don't have to do anything in particular and the grading of the project will be done as explained in the section \"Rubric for Individual Submissions\"\n",
    "\n",
    "## Working with a Partner\n",
    "\n",
    "If you decide to WORK IN PAIRS, you will have to have to send an email and will be required to do extra work in comparison to students working alone.\n",
    "\n",
    "Send an email to the Head TA, Sergio at sfaguile@gatech.edu, by the Friday, September 4th. After this date, if you haven't sent the email, you will have to work alone.\n",
    "The email's subject should be \n",
    "\n",
    "[CS6476] Project 1 - Work in Pairs - [student1] and [student2]\n",
    "\n",
    "Where [student1] is the first and last name of student 1 and [student2] is the first and last name of student 2.\n",
    "Inside the email, please add your names again and your GTIDs respectively. If [student1] sends the email, he must CC [student2] on the email.\n",
    "\n",
    "Both of you will follow the section \"Rubric for Partner Submissions\" to see which extra credit is required from you. \n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "The goal of this assignment is to write an image filtering function and use it to create hybrid images using a simplified version of the SIGGRAPH 2006 [paper](misc/oliva-siggraph-2006.pdf) by Oliva, Torralba, and Schyns. _Hybrid images_ are static images that change in interpretation as a function of the viewing distance. The basic idea is that high frequency tends to dominate perception when it is available but, at a distance, only the low frequency (smooth) part of the signal can be seen. By blending the high frequency portion of one image with the low-frequency portion of another, you get a hybrid image that leads to different interpretations at different distances.\n",
    "\n",
    "This project is intended to build upong the basic Pytorch we did in project 0, and introduce image filtering. Once you have created an image filtering function, it is relatively straightforward to construct hybrid images. If you don't already know Python, you may find [this resource](https://docs.python.org/3/tutorial/) helpful. If you're unfamiliar with PyTorch, the [tutorials](https://pytorch.org/tutorials/) from the official website are useful.\n",
    "\n",
    "We provide you with 5 pairs of aligned images which can be merged reasonably well into hybrid images. The alignment is super important because it affects the perceptual grouping (read the paper for details). We encourage you to create additional examples (e.g. change of expression, morph between different objects, change over time, etc.).\n",
    "\n",
    "![Hybrid Image](https://dellaert.github.io/19F-4476/images/proj1/hybrid_image.jpg)\n",
    "\n",
    "For the above example, the two original images look like this:\n",
    "\n",
    "![Dog](https://dellaert.github.io/19F-4476/images/proj1/dog.jpg)\n",
    "\n",
    "![Cat](https://dellaert.github.io/19F-4476/images/proj1/cat.jpg)\n",
    "\n",
    "The low-pass (blurred) and high-pass versions of these images look like this:\n",
    "\n",
    "![Low Frequencies](https://dellaert.github.io/19F-4476/images/proj1/low_frequencies.jpg)\n",
    "\n",
    "![High Frequencies](https://dellaert.github.io/19F-4476/images/proj1/high_frequencies.jpg)\n",
    "\n",
    "The high frequency image is actually zero-mean with negative values, so it is visualized by adding 0.5. In the resulting visualization, bright values are positive and dark values are negative.\n",
    "\n",
    "Adding the high and low frequencies together gives you the image at the top of this page. If you're having trouble seeing the multiple interpretations of the image, a useful way to visualize the effect is by progressively downsampling the hybrid image as is done below:\n",
    "\n",
    "![Cat Hybrid Image Scales](https://dellaert.github.io/19F-4476/images/proj1/cat_hybrid_image_scales.jpg)\n",
    "\n",
    "The starter code provides a function, `vis_image_scales_numpy()` in `utils.py`, which can be used to save and display such visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from proj1_code.utils import load_image, save_image, verify\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : 1D filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment relies on the concept of filtering signals. A [low pass filter](https://en.wikipedia.org/wiki/Low-pass_filter) removes the high-frequency components of a signal. \n",
    "\n",
    "To demonstarte the concepts of filtering in 1-D, we will use simple sine waves. These waves have just one frequency component and hence it will be easy to understand the effects of filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Sinusoids\n",
    "\n",
    "In this part, we will understand the concept behind low pass filtering and implemented a Gaussian-kernel based low-pass filtering.\n",
    "\n",
    "Let us start with [sinusoids](https://en.wikipedia.org/wiki/Sine_wave) in 1D: sinusoids are a family of sine functions with varying frequency, amplitude, and phase.\n",
    "\n",
    "$$f(x) = A \\text{sin} \\left(2 \\pi \\omega x + \\phi \\right)$$\n",
    "\n",
    "where $A$ is the amplitude, $\\omega$ is the frequency, and $\\phi$ is the phase.\n",
    "\n",
    "Let us now go through a utility function which will generate sinusoids for us for $x \\in [0, 5]$ given the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 40 # sampling frequency (i.e number of samples of x per second)\n",
    "x = torch.linspace(0, 5, int(5*fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_1d_sinusoid(amplitude: float, frequency: float, phase: float) -> torch.Tensor:\n",
    "    '''Generates sinusoids with given parameters on input x.'''\n",
    "    \n",
    "    return amplitude * torch.sin(2 * math.pi * frequency * x + phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following function to plot 1D signals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1d_signals(x: torch.Tensor, y_list: List[torch.Tensor], y_labels: List[str]):\n",
    "    plt.figure()\n",
    "    \n",
    "    for (y, label) in zip(y_list, y_labels):\n",
    "        plt.plot(x, y, label=label)\n",
    "        \n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate two sinusoids: one low frequency and one high frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq_sinusoid = generate_1d_sinusoid(1, 0.4, 0)\n",
    "high_freq_sinusoid = generate_1d_sinusoid(1, 4, 0)\n",
    "plot_1d_signals(x, [low_freq_sinusoid, high_freq_sinusoid], ['low_freq', 'high_freq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now linearly combine both the sinusoids to create a new **combined signal**. This signal will serve as an example for low-pass filters where will try to recover the low-frequency sinusoid back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear addition of low_freq and high_freq sinusoid\n",
    "combined_signal = low_freq_sinusoid + high_freq_sinusoid\n",
    "plot_1d_signals(x, [combined_signal], ['complex_signal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a signal with two frequency components. This can be useful to demonstrate low-pass filtering. Recall that low-pass filtering attenuates high-frequency components heavily, whereas the low-frequency components are left unchanged.\n",
    "\n",
    "We will now design a low pass filter which recovers the low-frequency component from the combined signal.\n",
    "\n",
    "Averaging operation is a good example of a low-pass filter. In this project, we will use averaging with Gaussian weights as a low-pass filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 1D Gaussian as Low-Pass filters\n",
    "\n",
    "A 1D Gaussian filter is of size $k$ is defined as: $$p(x; \\mu, \\sigma) = \\frac{1}{Z} \\exp \\left( -\\frac{\\left( x - \\mu \\right)^2}{2 \\sigma^2} \\right)$$\n",
    "where $Z$ is the normalizing coefficient such that the kernel sums to 1 over the range of the input $x \\in [0, k)$, $x$ being integers.\n",
    "\n",
    "The parameters $\\mu$ and $\\sigma$ are related to $k$ as:\n",
    "* kernel size $k = 4*\\sigma + 1$\n",
    "* mean $\\mu = \\lfloor\\frac{k}{2}\\rfloor$\n",
    "\n",
    "If we want to use this Gaussian kernel as a low-pass filter with cutoff frequency $\\omega_c$ (i.e. allow components with frequency $\\omega < \\omega_c$ pass through and attenuate components with higher frequency), we need to define the kernel parameters as follows:\n",
    "* standard deviation $\\sigma = \\frac{f_s}{2 \\pi \\omega_c}$.\n",
    "\n",
    "We can hence use $\\sigma$ as the paramterization of the kernel in this project. We can derive $k$ and $\\mu$ using $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO 1**: implement the function `create_1D_Gaussian_kernel` in file `models.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.models import create_1D_Gaussian_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to visualize kernel\n",
    "def plot_kernel(kernel: torch.Tensor):\n",
    "    '''Plots the kernel'''\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(kernel)\n",
    "    plt.xlabel('idx')\n",
    "    plt.ylabel('p')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two components at frequency 0.4 and 4. Hence lets use 1.5 as the cutoff frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_frequency = 1.5\n",
    "standard_deviation = fs/(2*math.pi*cutoff_frequency)\n",
    "\n",
    "lowpass_1dfilter = create_1D_Gaussian_kernel(standard_deviation)\n",
    "\n",
    "plot_kernel(lowpass_1dfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proj1_code.proj1_unit_tests.test_create_1D_Gaussian_kernel as test_create_1D_Gaussian_kernel\n",
    "\n",
    "print('test_tensor_datatype: ', \n",
    "      verify(test_create_1D_Gaussian_kernel.test_tensor_datatype))\n",
    "print('test_create_kernel_with_sigma_int: ', \n",
    "      verify(test_create_1D_Gaussian_kernel.test_create_kernel_with_sigma_int))\n",
    "print('test_kernel_sum: ',\n",
    "      verify(test_create_1D_Gaussian_kernel.test_kernel_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**:\n",
    "* Does the plot look like a Gaussian function?\n",
    "* Does the unit test(s) pass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Applying low-pass filter on combined signal (combination of sinusoids with two different frequencies)\n",
    "\n",
    "We want to use the Gaussian kernel we created to filter out the high frequency sinusoid. For this, you need to implement the function to perform 1D filtering. Let's check that our low-pass filter using Gaussian kernel is working as expected by filtering the low pass and high pass signal separately.\n",
    "\n",
    "**TODO 2**: implement the function `my_1dfilter` in file `part1.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.part1 import my_1dfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying on low frequency signal\n",
    "filtered_low_freq_sinusoid = my_1dfilter(low_freq_sinusoid, lowpass_1dfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1d_signals(x, [low_freq_sinusoid, filtered_low_freq_sinusoid], ['input', 'output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying on low frequency signal\n",
    "filtered_high_freq_sinusoid = my_1dfilter(high_freq_sinusoid, lowpass_1dfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the input\n",
    "plot_1d_signals(x, [high_freq_sinusoid, filtered_high_freq_sinusoid], ['input', 'output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proj1_code.proj1_unit_tests.test_my_1dfilter as test_my_1dfilter\n",
    "\n",
    "print('test_filter_with_box_kernel: ', \n",
    "      verify(test_my_1dfilter.test_filter_with_box_kernel))\n",
    "print('test_filter_with_asymmetric_kernel: ', \n",
    "      verify(test_my_1dfilter.test_filter_with_asymmetric_kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**:\n",
    "* Does the filter attenuate the high-frequency signal by a large magnitute, but the low-frequency signal is relatively unaffected\n",
    "* Does the unit test(s) pass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets observe what happens when we apply this filter to the combined signal\n",
    "filtered_combined_signal = my_1dfilter(combined_signal, lowpass_1dfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1d_signals(x, [combined_signal, filtered_combined_signal, low_freq_sinusoid], ['input', 'output', 'original_low_freq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Implementing hybrid images in Pytorch manually\n",
    "\n",
    "**Gaussian Kernels.** Gaussian filters are used for blurring images.\n",
    "\n",
    "The multivariate Gaussian function is defined as:\n",
    "\n",
    "$$p(x;\\mu, \\Sigma) = \\frac{1}{(2\\pi)^{n/2}\\det(\\Sigma)^{1/2}}\\exp\\bigg(-\\frac{1}{2}(x-\\mu)^\\top\\Sigma^{-1}(x-\\mu)\\bigg)$$\n",
    "\n",
    "where $n$ is equal to the dimension of $x$, $\\mu$ is the mean, and $\\Sigma$ is the covariance matrix. Similar to 1.2, we will use $\\sigma$ as the hyperparameter of the 2D kernel. The kernel shape is $(k,k)$ and the mean is $\\mu$ in each dimension. They are related to $\\sigma$ as:\n",
    "- $k = 4*\\sigma + 1$\n",
    "- $\\mu= \\begin{bmatrix} \\lfloor\\frac{k}{2}\\rfloor \\\\ \\lfloor\\frac{k}{2}\\rfloor \\end{bmatrix}$\n",
    "- $\\Sigma = \\begin{bmatrix} \\sigma^2 & 0 \\\\ 0 & \\sigma^2 \\end{bmatrix}$\n",
    "\n",
    "Alternatively, you can create a 2D Gaussian by taking the outer product of two vectors. Each such vector should have values populated from evaluating the 1D Gaussian PDF at each coordinate. The 1D Gaussian, as we saw in part 1.2, is defined as:\n",
    "$$p(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\mbox{exp} \\Bigg(-\\frac{1}{2\\sigma^2}(x-\\mu)^2 \\Bigg)$$\n",
    "\n",
    "\n",
    "\n",
    "Note that the sum of values in the 2D kernel should sum to 1.\n",
    "\n",
    "You will be implementing `create_2D_Gaussian_kernel()` that creates a 2D Gaussian kernel according to a free parameter, _standard deviation_, which controls how much low frequency to leave in the image. This is an important step for later in the project when you create hybrid images!\n",
    "\n",
    "**Image Filtering.** Image filtering (or convolution) is a fundamental image processing tool. See chapter 3.2 of Szeliski and the lecture materials to learn about image filtering (specifically linear filtering). You will be writing your own function to implement image filtering from scratch. More specifically, you will implement `my_imfilter()` which imitates the `filter2D()` function in the OpenCV library. As specified in `part2.py`, your filtering algorithm must: (1) support grayscale and color images, (2) support arbitrarily-shaped filters, as long as both dimensions are odd (e.g. 7x9 filters, but not 4x5 filters), (3) pad the input image with zeros or reflected image content, and (4) return a filtered image which is the same resolution as the input image. We have provided an iPython notebook, `proj1_test_filtering.ipynb`, along with some tests (which are called in `proj1.ipynb`) to help you debug your image filtering algorithm. Note that there is a time limit of 5 minutes for a single call to `my_imfilter()`, so try to optimize your implementation if it goes over.\n",
    "\n",
    "**Hybrid Images.** A hybrid image is the sum of a low-pass filtered version of one image and a high-pass filtered version of another image. As mentioned in above, _cutoff standarddeviation_ controls how much high frequency to leave in one image and how much low frequency to leave in the other image. In `cutoff_standarddeviation.txt`, we provide a default value of 7 for each pair of images (the value on line _i_ corresponds to the cutoff value for the _i_-th image pair). You should replace these values with the ones you find work best for each image pair. In the paper it is suggested to use two cutoff (one tuned for each image) and you are free to try that as well. You will first implement `create_hybrid_image()` according to the starter code in `part2.py`. Your function will call `my_imfilter()` using the kernel generated from `create_Gaussian_kernel()` to create low and high frequency images and then combine them into a hybrid image.\n",
    "\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.utils import load_image, save_image\n",
    "\n",
    "image1 = load_image('data/1a_dog.bmp')\n",
    "image2 = load_image('data/1b_cat.bmp')\n",
    "\n",
    "# display the dog and cat images\n",
    "plt.figure(figsize=(3,3)); plt.imshow((image1*255).byte())\n",
    "plt.figure(figsize=(3,3)); plt.imshow((image2*255).byte());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create filter\n",
    "\n",
    "**TODO 3**: You will first need to implement `create_2D_Gaussian_kernel()` in `models.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.part2 import create_hybrid_image, my_imfilter\n",
    "from proj1_code.models import create_2D_Gaussian_kernel\n",
    "from proj1_code.proj1_unit_tests.test_2d import verify_gaussian_kernel\n",
    "\n",
    "cutoff_standard_deviation = 7\n",
    "kernel = create_2D_Gaussian_kernel(cutoff_standard_deviation)\n",
    "\n",
    "# let's take a look at the filter!\n",
    "plt.figure(figsize=(4,4)); plt.imshow(kernel);\n",
    "\n",
    "## Verify that the Gaussian kernel was created correctly\n",
    "print(verify_gaussian_kernel(kernel, cutoff_standard_deviation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply filter to image\n",
    "\n",
    "**TODO 4**: The next two functions you need to implement in this project can also be found in `part2.py`. Start by implementing `my_imfilter`, which takes both a filter and an image, and returns the filtered image. This code block will use your `my_imfilter` function to create and display a blurry version of image1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurry_image = my_imfilter(image1, kernel)\n",
    "\n",
    "plt.figure(); plt.imshow((blurry_image*255).byte());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hybrid image\n",
    "\n",
    "**TODO 5**: Next, implement `create_hybrid_image()` in `part2.py`, which takes two images and makes a hybrid image using the low frequency content from one image and the high frequency content from another by applying the Gaussian kernel you defined in `create_2D_Gaussian_kernel()`.\n",
    "\n",
    "Experiment with the value of `cutoff_standarddeviation` for each pair of images in `data/`. For each image pair, replace `cutoff_standarddeviations.txt` with the best cutoff standard deviation value you find. The value on line *i* of the text file should correspond to _i_-th image pair. This is an important step for the next part! Feel free to also experiment with which image in each pair you grab the low frequencies from and which image you grab high frequencies from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_code.utils import vis_image_scales_numpy\n",
    "\n",
    "from proj1_code.proj1_unit_tests.test_2d import (\n",
    "    verify_low_freq_sq_kernel_torch_manual,\n",
    "    verify_high_freq_sq_kernel_torch_manual,\n",
    "    verify_hybrid_image_torch_manual\n",
    ")\n",
    "low_frequencies, high_frequencies, hybrid_image = create_hybrid_image(image1, image2, kernel)\n",
    "\n",
    "## Verify that results are as expected\n",
    "print(verify_low_freq_sq_kernel_torch_manual(image1, kernel, low_frequencies))\n",
    "print(verify_high_freq_sq_kernel_torch_manual(image2, kernel, high_frequencies))\n",
    "print(verify_hybrid_image_torch_manual(image1, image2, kernel, hybrid_image))\n",
    "\n",
    "vis = vis_image_scales_numpy(hybrid_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(); plt.imshow((low_frequencies*255).byte());\n",
    "plt.figure(); plt.imshow(((high_frequencies+0.5)*255).byte());\n",
    "plt.figure(figsize=(20, 20)); plt.imshow(vis);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image('../results/part2/low_frequencies.jpg', low_frequencies)\n",
    "save_image('../results/part2/high_frequencies.jpg', high_frequencies+0.5)\n",
    "save_image('../results/part2/hybrid_image.jpg', hybrid_image)\n",
    "save_image('../results/part2/hybrid_image_scales.jpg', vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Using PyTorch's inbuilt operators\n",
    "\n",
    "**Dataloader.** **(TODO 6)**: You will now implement creating hybrid images again but using PyTorch. The `HybridImageDataset` class in `datasets.py` will create tuples using pairs of images with a corresponding cutoff standard deviation (which you should have found from experimenting in Part 2). The images will be loaded from `data/` and the cutoff standard deviation from `cutoff_standarddeviations.txt`. Refer to [this tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) for additional information on data loading & processing.\n",
    "\n",
    "**Model.** **(TODO 7)**: Next, you will implement the `HybridImageModel` class in `models.py`. Instead of using your implementation of `my_imfilter()` to get the low and high frequencies from a pair of images, `low_pass()` should use the 2d convolution operator from `torch.nn.functional` to apply a low pass filter to a given image. You will have to implement `get_kernel()` which calls your `create_Gaussian_kernel()` function from `models.py` for each pair of images using the cutoffs as specified in `cutoff_standarddeviations.txt` and reshapes it to the appropriate dimensions for PyTorch. Then, similar to `create_hybrid_image()` from Part 2, `forward()` will call `get_kernel()` and `low_pass()` to create the low and high frequency images and combine them into a hybrid image. Refer to [this tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html) for additional information on defining neural networks using PyTorch.\n",
    "\n",
    "Lastly, you will compare the runtimes of your hybrid image implementations from Parts 2 and 3.\n",
    "\n",
    "Make sure you have specified a cutoff value in `cutoff_standarddeviations.txt` for each image pair in `data/` before executing the following blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from proj1_code.datasets import HybridImageDataset\n",
    "from proj1_code.models import HybridImageModel\n",
    "\n",
    "\n",
    "data_root = 'data/' # if you're using additional data, make sure to change this to '../additional_data'\n",
    "cf_file = 'cutoff_standarddeviations.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model & dataset\n",
    "Implement `HybridImageModel` and `HybridImageDataset`, found in `models.py` and `datasets.py`, respectively.\n",
    "\n",
    "In the code documentation, you will see a term called \"batch size\", which we will discuss in later projects and lectures. For now, we are using the default value of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridImageModel()\n",
    "dataset = HybridImageDataset(data_root, cf_file)\n",
    "dataloader = torch.utils.data.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hybrid images\n",
    "This code block will iterate through pairs of images from your dataset and create a hybrid image using the low frequency content from one image and the high frequency content from another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(dataloader):\n",
    "    image_a, image_b, cutoff_standarddeviation = sample\n",
    "    low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, cutoff_standarddeviation)\n",
    "    \n",
    "    # saves low frequencies, high frequencies, and hybrid image of each pair of images\n",
    "    torchvision.utils.save_image(low_frequencies, '../results/part3/%d_low_frequencies.jpg' % i)\n",
    "    torchvision.utils.save_image(high_frequencies+0.5, '../results/part3/%d_high_frequencies.jpg' % i)\n",
    "    torchvision.utils.save_image(hybrid_image, '../results/part3/%d_hybrid_image.jpg' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify that the results are correct, with cutoff_frequency of 7\n",
    "from proj1_code.proj1_unit_tests.test_2d import (\n",
    "    verify_low_freq_sq_kernel_pytorch, \n",
    "    verify_high_freq_sq_kernel_pytorch,\n",
    "    verify_hybrid_image_pytorch\n",
    ")\n",
    "\n",
    "dataset = HybridImageDataset(data_root, cf_file)\n",
    "dataloader = torch.utils.data.DataLoader(dataset)\n",
    "image_a, image_b, cutoff = next(iter(dataloader))\n",
    "low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, cutoff)\n",
    "\n",
    "cutoff_sd = torch.Tensor([7])\n",
    "## On first dog/cat pair, verify that the Pytorch results are as expected\n",
    "print(verify_low_freq_sq_kernel_pytorch(image_a, model, cutoff_sd, low_frequencies))\n",
    "print(verify_high_freq_sq_kernel_pytorch(image_b, model, cutoff_sd, high_frequencies))\n",
    "## Verify that the Pytorch hybrid images are created correctly\n",
    "print(verify_hybrid_image_pytorch(image_a, image_b, model, cutoff_sd, hybrid_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid image timing comparison\n",
    "Here, we will compare the runtime of creating hybrid images using your manual Torch implementation to the PyTorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "image1 = load_image('data/1a_dog.bmp')\n",
    "image2 = load_image('data/1b_cat.bmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing Part 2. Notice that we explicitly include `create_2D_Gaussian_kernel()` in the timing of Part 2 but not Part 3. This is because the function is already being called (and therefore timed) inside the forward pass of `HybridImageModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cutoff_standarddeviation = 7\n",
    "kernel = create_2D_Gaussian_kernel(cutoff_standarddeviation)\n",
    "low_frequencies, high_frequencies, hybrid_image = create_hybrid_image(image1, image2, kernel)\n",
    "end = time.time() - start\n",
    "print('Part 1: {:.3f} seconds'.format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridImageModel()\n",
    "\n",
    "start = time.time()\n",
    "low_frequencies, high_frequencies, hybrid_image = model(image_a, image_b, torch.Tensor([cutoff_standarddeviation]))\n",
    "end = time.time() - start\n",
    "print('Part 2: {:.3f} seconds'.format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit\n",
    "\n",
    "In this section, we will learn about formulating the Discrete Fourier Transform matrix, and use it to run DFT for 2D images, and implement a low-pass filter based on your DFT analysis results. \n",
    "\n",
    "### DFT for 2D signal\n",
    "\n",
    "An N-point DFT is expressed as the multiplication $X=Wx$, where $x$ is the original input signal, $W$ is the N-by-N square DFT matrix, and $X$ is the DFT of the signal. The [wiki](https://en.wikipedia.org/wiki/DFT_matrix) provides a good introduction on DFT matrix for a 1D signal. The DFT equation for a 2D square matrix is:\n",
    "$$U_{mn}=\\frac{1}{M}e^{-j\\frac{2\\pi mn}{M}}$$\n",
    "where $M=N$. \n",
    "\n",
    "**TODO** Implement the `DFT_matrix` in `dft.py` function based on the given information. (REQUIRED FOR STUDENTS WORKING IN PAIRS)\n",
    "\n",
    "In this part, we begin with a simple situation where we assume all the 2D image matrices are square, grayscale matrices, which would make your life easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_unit_tests.test_dft import test_dft_matrix\n",
    "\n",
    "print(test_dft_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image filtering based on Discrete Fourier Transform (DFT)\n",
    "\n",
    "A brief review on the DFT for 2D images:\n",
    "$$F[k,l]=\\sum_{m=0}^{M-1}\\sum_{n=0}^{N-1}f[m,n]exp(-j\\frac{2\\pi}{M}km-j\\frac{2\\pi}{N}ln)$$\n",
    "where $$0\\leq k \\leq M-1$$ $$0\\leq l \\leq N-1$$\n",
    "\n",
    "We observe that the DFT transform of each row is independent from that of the column. This means in order to obtain the 2D DFT transform, we can run a 1D DFT of then columns, then a 1D DFT of rows consecutively (or rows first, then columns). That would save us a lot of computation!\n",
    "\n",
    "**TODO** We can now use the `DFT_matrix` function in `dft.py` to generate DFT for a normal image, and implement the function `my_dft`. (REQUIRED FOR STUDENTS WORKING IN PAIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_unit_tests.test_dft import test_dft\n",
    "\n",
    "print(test_dft())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate low-pass filter!\n",
    "\n",
    "Finally, we implement a low-pass filter based on your own DFT, and add the results of the following images to your report. :`data_part4/6a_dog.bmp`, `data_part4/6b_cat.bmp`; the resolution is 512x512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "from proj1_code.dft import dft_filter\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "image6 = Image.open('data_part4/6a_dog.bmp')\n",
    "image_gray = transforms.ToTensor()(image6)[0,:,:]\n",
    "img_dft_filter = dft_filter(image_gray)\n",
    "\n",
    "plt.subplot(121), plt.imshow(image_gray, cmap = 'gray')\n",
    "plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(img_dft_filter, cmap = 'gray')\n",
    "plt.title('Filtered Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impresive Hybrid Images\n",
    "\n",
    "It is also possible to get extra credit for this project as well if you come up with some clever hybrid images which impress the TAs and Frank. Additionally, you should add slides at the end of your report further showing your results. The best ones get a special mention from Frank at the beginning of one of the future lectures!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forbidden functions\n",
    "\n",
    "You can use these for testing, but not in your final code: anything that takes care of the filtering operation or creates a 2D Gaussian kernel directly for you. ex. (cv2.getGaussianKernel) If it feels like you're sidestepping the work, then it's probably not allowed. Ask the TAs if you have any doubts.\n",
    "\n",
    "# Code Testing\n",
    "\n",
    "We have provided a set of tests for you to evaluate your implementation. We have included tests inside `proj1.ipynb` so you can check your progress as you implement each section. When you're done with the entire project, you can call additional tests by running `pytest proj1_unit_tests` inside the `proj1_code` directory of the project. _Your grade on the coding portion of the project will be further evaluated with a set of tests not provided to you._\n",
    "\n",
    "# Writeup\n",
    "\n",
    "For this project (and all other projects), you must do a project report using the template slides provided to you at \"proj1_template.pptx\". Do <u>not</u> change the order of the slides or remove any slides, as this will affect the grading process on Gradescope and you will be deducted points. In the report you will describe your algorithm and any decisions you made to write your algorithm a particular way. Then you will show and discuss the results of your algorithm. The template slides provide guidance for what you should include in your report. A good writeup doesn't just show results--it tries to draw some conclusions from the experiments. You must convert the slide deck into a PDF with the name `<your_gt_username.pdf>` for your submission.\n",
    "\n",
    "If you choose to do anything extra, add slides _after the slides given in the template deck_ to describe your implementation, results, and analysis. Adding slides in between the report template will cause issues with Gradescope, and you will be deducted points. You will not receive full credit for your extra credit implementations if they are not described adequately in your writeup.\n",
    "\n",
    "## Working with a Partner\n",
    "\n",
    "If you are working with a Partner, both of you can have the same results and analysis. However, you must answer the \"meta-learning\" questions individually, these questions are marked with a red message on the slide. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rubric for Individual Submissions\n",
    "\n",
    "* +6 pts: `my_1dfilter()` in `part2.py`\n",
    "* +15 pts: `my_imfilter()` in `part2.py`\n",
    "* +5 pts: `create_hybrid_image()` in `part2.py`\n",
    "* +5 pts: `__init__()` in `datasets.py` for transforms.\n",
    "* +5 pts: `__len__()` in `datasets.py`\n",
    "* +5 pts: `__getitem__()` in `datasets.py`\n",
    "* +4 pts: `create_1D_Gaussian_kernel()` in `models.py`\n",
    "* +4 pts: `create_2D_Gaussian_kernel()` in `models.py`\n",
    "* +5 pts: `low_pass()` in `models.py`\n",
    "* +15 pts: `forward()` in `models.py`\n",
    "* +31 pts: Report with outputs and reflections\n",
    "* -5\\*n pts: Lose 5 points for every time you do not follow the instructions for the hand-in format.\n",
    "\n",
    "EC:\n",
    "\n",
    "* +2 pts: `DFT_matrix` in dft.py\n",
    "* +4 pts: `my_dft` in dft.py\n",
    "* +4 pts: `dft_filter` results in the report.\n",
    "* +2-5: Additional hybrid images, graded on creativity and originality\n",
    "\n",
    "\n",
    "# Rubric for Partner Submissions\n",
    "\n",
    "* +6 pts: `my_1dfilter()` in `part2.py`\n",
    "* +12 pts: `my_imfilter()` in `part2.py`\n",
    "* +4 pts: `create_hybrid_image()` in `part2.py`\n",
    "* +4 pts: `__init__()` in `datasets.py` for transforms.\n",
    "* +4 pts: `__len__()` in `datasets.py`\n",
    "* +4 pts: `__getitem__()` in `datasets.py`\n",
    "* +4 pts: `create_1D_Gaussian_kernel()` in `models.py`\n",
    "* +4 pts: `create_2D_Gaussian_kernel()` in `models.py`\n",
    "* +4 pts: `low_pass()` in `models.py`\n",
    "* +9 pts: `forward()` in `models.py`\n",
    "* +6 pts: `DFT_matrix` in dft.py\n",
    "* +8 pts: `my_dft` in dft.py\n",
    "* +31 pts: Report with outputs and reflections\n",
    "* -5\\*n pts: Lose 5 points for every time you do not follow the instructions for the hand-in format.\n",
    "\n",
    "EC:\n",
    "* +4 pts: `dft_filter` results in the report.\n",
    "* +2-5: Additional hybrid images, graded on creativity and originality\n",
    "\n",
    "\n",
    "\n",
    "# Submission\n",
    "\n",
    "This is very important as you will lose 5 points for every time you do not follow the instructions. \n",
    "\n",
    "Do <u>not</u> install any additional packages inside the conda environment. The TAs will use the same environment as defined in the config files we provide you, so anything that's not in there by default will probably cause your code to break during grading. Do <u>not</u> use absolute paths in your code or your code will break. Use relative paths like the starter code already does. Failure to follow any of these instructions will lead to point deductions. Create the zip file using `python zip_submission.py --gt_username <your_gt_username>` (it will zip up the appropriate directories/files for you!) and hand it through Gradescope. Remember to submit your report as a PDF to Gradescope as well.\n",
    "\n",
    "## Working Alone\n",
    "\n",
    "You will have two submission files for this project:\n",
    "\n",
    "1. `<your_gt_username>.zip` via **Gradescope** to assignment [Project 1 - Code (Individual)](https://www.gradescope.com/courses/155064/assignments/590378) containing:\n",
    "    * `proj1_code/` - directory containing all your code for this assignment\n",
    "    * `proj1_code/cutoff_standarddeviations.txt` - .txt file containing the best cutoff standard deviation values you found for each pair of images in `data/`.\n",
    "    * `additional_data/` - (optional) if you use any data other than the images we provide you, please include them here\n",
    "    * `README.txt` - (optional) if you implement any new functions other than the ones we define in the skeleton code (e.g. any extra credit implementations), please describe what you did and how we can run the code. We will not award any extra credit if we can't run your code and verify the results. \n",
    "2. `<your_gt_username>.pdf` via **Gradescope** to assignment [Project 1 - Report](https://www.gradescope.com/courses/155064/assignments/601658) - your report\n",
    "\n",
    "## Working with a Partner\n",
    "\n",
    "Both students must SEPARATELY submit two files for this project:\n",
    "\n",
    "1. `<your_gt_username>.zip` via **Gradescope** to assignment [Project 1 - Code (Partner)](https://www.gradescope.com/courses/155064/assignments/637442) containing:\n",
    "    * `proj1_code/` - directory containing all your code for this assignment\n",
    "    * `proj1_code/cutoff_standarddeviations.txt` - .txt file containing the best cutoff standard deviation values you found for each pair of images in `data/`.\n",
    "    * `additional_data/` - (optional) if you use any data other than the images we provide you, please include them here\n",
    "    * `README.txt` - (optional) if you implement any new functions other than the ones we define in the skeleton code (e.g. any extra credit implementations), please describe what you did and how we can run the code. We will not award any extra credit if we can't run your code and verify the results.\n",
    "2. `<your_gt_username>.pdf` via **Gradescope** to assignment [Project 1 - Report](https://www.gradescope.com/courses/155064/assignments/601658) - your report\n",
    "\n",
    "# Credit\n",
    "Assignment developed by Arvind Krishnakumar, Ayush Baid, Sen Wang and Frank Dellaert, based on a similar project by James Hays, Derek Hoiem, Cusuh Ham, John Lambert and Samarth Brahmbhatt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}